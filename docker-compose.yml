services:
  # ----------------------------------------------------------
  # INFRASTRUCTURE
  # ----------------------------------------------------------
  postgres:
    image: ankane/pgvector:latest
    container_name: refinery_postgres
    restart: unless-stopped
    environment:
      POSTGRES_USER: ${POSTGRES_USER:-refinery}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-refinery}
      POSTGRES_DB: refinery
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./db/init.sql:/docker-entrypoint-initdb.d/init.sql
    ports:
      - "127.0.0.1:5432:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER:-refinery} -d refinery"]
      interval: 5s
      timeout: 5s
      retries: 10
    networks:
      - refinery

  redis:
    image: redis:7
    container_name: refinery_redis
    restart: unless-stopped
    command: >
      sh -c "if [ -f /etc/redis/secrets/redis.conf ]; then
        redis-server /etc/redis/secrets/redis.conf;
      else
        redis-server;
      fi"
    volumes:
      - ./secrets:/etc/redis/secrets:ro
    ports:
      - "127.0.0.1:6379:6379"
    healthcheck:
      test: ["CMD", "redis-cli", "-a", "${REDIS_PASSWORD:-}", "ping"]
      interval: 5s
      timeout: 3s
      retries: 10
    networks:
      - refinery

  minio:
    image: minio/minio
    container_name: refinery_minio
    restart: unless-stopped
    command: server /data --console-address ":9001"
    environment:
      MINIO_ROOT_USER: ${MINIO_ROOT_USER:-minioadmin}
      MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD:-minioadmin}
    ports:
      - "127.0.0.1:9000:9000"
      - "127.0.0.1:9001:9001"
    volumes:
      - minio_data:/data
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - refinery

  searxng:
    image: searxng/searxng:latest
    container_name: refinery_searxng
    restart: unless-stopped
    volumes:
      - ./searxng/settings.yml:/etc/searxng/settings.yml:ro
    environment:
      SEARXNG_BASE_URL: "http://searxng:8080/"
    ports:
      - "127.0.0.1:8080:8080"
    healthcheck:
      test: ["CMD-SHELL", "python3 -c \"import urllib.request; urllib.request.urlopen('http://localhost:8080/')\""]
      interval: 15s
      timeout: 5s
      retries: 5
      start_period: 15s
    networks:
      - refinery

  # ----------------------------------------------------------
  # LLM SERVICES (GPU-accelerated Ollama instances)
  # GPU assignment via device_ids ensures each container only
  # sees its assigned GPU. Set in .env:
  #   GPU_EMBED=0  (Quadro P1000 4GB - nomic-embed-text)
  #   GPU_REASON=1 (RTX 3080 10GB   - mistral reasoning + reason2)
  # ----------------------------------------------------------
  llm-embed:
    image: ollama/ollama
    container_name: refinery_llm_embed
    restart: unless-stopped
    ports:
      - "127.0.0.1:11434:11434"
    volumes:
      - ollama_embed_data:/root/.ollama
    environment:
      OLLAMA_HOST: "0.0.0.0:11434"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ["${GPU_EMBED:-0}"]
              capabilities: [gpu]
    healthcheck:
      test: ["CMD", "ollama", "list"]
      interval: 15s
      timeout: 10s
      retries: 10
      start_period: 30s
    networks:
      - refinery

  llm-reason:
    image: ollama/ollama
    container_name: refinery_llm_reason
    restart: unless-stopped
    ports:
      - "127.0.0.1:11435:11434"
    volumes:
      - ollama_reason_data:/root/.ollama
    environment:
      OLLAMA_HOST: "0.0.0.0:11434"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ["${GPU_REASON:-0}"]
              capabilities: [gpu]
    healthcheck:
      test: ["CMD", "ollama", "list"]
      interval: 15s
      timeout: 10s
      retries: 10
      start_period: 30s
    networks:
      - refinery

  # Second reasoning instance on RTX 3080 (alongside primary reasoning)
  # Both reason + reason2 share the 3080's 10GB VRAM
  llm-reason2:
    image: ollama/ollama
    container_name: refinery_llm_reason2
    restart: unless-stopped
    volumes:
      - ollama_reason2_data:/root/.ollama
    environment:
      OLLAMA_HOST: "0.0.0.0:11434"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ["${GPU_REASON:-1}"]
              capabilities: [gpu]
    healthcheck:
      test: ["CMD", "ollama", "list"]
      interval: 15s
      timeout: 10s
      retries: 10
      start_period: 30s
    networks:
      - refinery

  # ----------------------------------------------------------
  # BACKEND API
  # ----------------------------------------------------------
  backend:
    build: ./backend
    container_name: refinery_backend
    restart: unless-stopped
    stop_grace_period: 10s
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      minio:
        condition: service_healthy
    environment:
      DATABASE_URL: ${DATABASE_URL:-postgresql://refinery:refinery@postgres:5432/refinery}
      REDIS_HOST: redis
      REDIS_PORT: "6379"
      REDIS_PASSWORD: ${REDIS_PASSWORD:-}
      MINIO_ENDPOINT: minio:9000
      MINIO_ACCESS_KEY: ${MINIO_ROOT_USER:-minioadmin}
      MINIO_SECRET_KEY: ${MINIO_ROOT_PASSWORD:-minioadmin}
      MINIO_BUCKET: documents
      OLLAMA_EMBED_URL: "http://llm-embed:11434"
      EMBEDDING_MODEL: nomic-embed-text
      API_KEYS: ${API_KEYS:-}
    ports:
      - "8000:8000"
    healthcheck:
      test: ["CMD-SHELL", "python -c \"import urllib.request; urllib.request.urlopen('http://localhost:8000/health')\""]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s
    networks:
      - refinery

  # ----------------------------------------------------------
  # WORKERS
  # ----------------------------------------------------------
  worker-chunking:
    build:
      context: ./workers
      dockerfile: chunking/Dockerfile
    container_name: refinery_worker_chunking
    restart: unless-stopped
    stop_grace_period: 10s
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      minio:
        condition: service_healthy
    environment:
      DATABASE_URL: ${DATABASE_URL:-postgresql://refinery:refinery@postgres:5432/refinery}
      REDIS_HOST: redis
      REDIS_PORT: "6379"
      REDIS_PASSWORD: ${REDIS_PASSWORD:-}
      MINIO_ENDPOINT: minio:9000
      MINIO_ACCESS_KEY: ${MINIO_ROOT_USER:-minioadmin}
      MINIO_SECRET_KEY: ${MINIO_ROOT_PASSWORD:-minioadmin}
      MINIO_BUCKET: documents
      WORKER_QUEUE: "jobs:chunk"
      NEXT_QUEUE: "jobs:embed"
    networks:
      - refinery

  worker-embedding:
    build:
      context: ./workers
      dockerfile: embedding/Dockerfile
    container_name: refinery_worker_embedding
    restart: unless-stopped
    stop_grace_period: 10s
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      llm-embed:
        condition: service_healthy
    environment:
      DATABASE_URL: ${DATABASE_URL:-postgresql://refinery:refinery@postgres:5432/refinery}
      REDIS_HOST: redis
      REDIS_PORT: "6379"
      REDIS_PASSWORD: ${REDIS_PASSWORD:-}
      OLLAMA_BASE_URL: "http://llm-embed:11434"
      EMBEDDING_MODEL: nomic-embed-text
      WORKER_QUEUE: "jobs:embed"
      NEXT_QUEUE: "jobs:evaluate"
    networks:
      - refinery

  worker-evaluation:
    build:
      context: ./workers
      dockerfile: evaluation/Dockerfile
    container_name: refinery_worker_evaluation
    restart: unless-stopped
    stop_grace_period: 10s
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      llm-reason:
        condition: service_healthy
    environment:
      DATABASE_URL: ${DATABASE_URL:-postgresql://refinery:refinery@postgres:5432/refinery}
      REDIS_HOST: redis
      REDIS_PORT: "6379"
      REDIS_PASSWORD: ${REDIS_PASSWORD:-}
      OLLAMA_BASE_URL: "http://llm-reason:11434"
      REASONING_MODEL: mistral
      WORKER_QUEUE: "jobs:evaluate"
      NEXT_QUEUE: "jobs:extract"
      SEARXNG_URL: "http://searxng:8080"
      EVAL_SEARCH_ENABLED: ${EVAL_SEARCH_ENABLED:-true}
    networks:
      - refinery

  worker-extraction:
    build:
      context: ./workers
      dockerfile: extraction/Dockerfile
    container_name: refinery_worker_extraction
    restart: unless-stopped
    stop_grace_period: 10s
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      llm-reason:
        condition: service_healthy
    environment:
      DATABASE_URL: ${DATABASE_URL:-postgresql://refinery:refinery@postgres:5432/refinery}
      REDIS_HOST: redis
      REDIS_PORT: "6379"
      REDIS_PASSWORD: ${REDIS_PASSWORD:-}
      OLLAMA_BASE_URL: "http://llm-reason:11434"
      REASONING_MODEL: mistral
      WORKER_QUEUE: "jobs:extract"
      NEXT_QUEUE: "jobs:resolve"
    networks:
      - refinery

  worker-conflict:
    build:
      context: ./workers
      dockerfile: conflict/Dockerfile
    container_name: refinery_worker_conflict
    restart: unless-stopped
    stop_grace_period: 10s
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    environment:
      DATABASE_URL: ${DATABASE_URL:-postgresql://refinery:refinery@postgres:5432/refinery}
      REDIS_HOST: redis
      REDIS_PORT: "6379"
      REDIS_PASSWORD: ${REDIS_PASSWORD:-}
      WORKER_QUEUE: "jobs:resolve"
      NEXT_QUEUE: ""
    networks:
      - refinery

  worker-crawler:
    build:
      context: ./workers
      dockerfile: crawler/Dockerfile
    container_name: refinery_worker_crawler
    restart: unless-stopped
    stop_grace_period: 10s
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      minio:
        condition: service_healthy
    environment:
      DATABASE_URL: ${DATABASE_URL:-postgresql://refinery:refinery@postgres:5432/refinery}
      REDIS_HOST: redis
      REDIS_PORT: "6379"
      REDIS_PASSWORD: ${REDIS_PASSWORD:-}
      MINIO_ENDPOINT: minio:9000
      MINIO_ACCESS_KEY: ${MINIO_ROOT_USER:-minioadmin}
      MINIO_SECRET_KEY: ${MINIO_ROOT_PASSWORD:-minioadmin}
      MINIO_BUCKET: documents
      WORKER_QUEUE: "jobs:crawl"
      NEXT_QUEUE: "jobs:chunk"
    networks:
      - refinery

  worker-verify:
    build:
      context: ./workers
      dockerfile: verify/Dockerfile
    container_name: refinery_worker_verify
    restart: unless-stopped
    stop_grace_period: 10s
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    environment:
      DATABASE_URL: ${DATABASE_URL:-postgresql://refinery:refinery@postgres:5432/refinery}
      REDIS_HOST: redis
      REDIS_PORT: "6379"
      REDIS_PASSWORD: ${REDIS_PASSWORD:-}
      OPENAI_API_KEYS: ${OPENAI_API_KEYS:-}
      VERIFY_MODEL: ${VERIFY_MODEL:-gpt-4o-mini}
      VERIFY_INTERVAL: "30"
      VERIFY_BATCH_SIZE: "5"
    networks:
      - refinery

  # ----------------------------------------------------------
  # MONITORING & SELF-HEALING
  # ----------------------------------------------------------
  monitor-agent:
    build:
      context: ./workers
      dockerfile: monitoring/Dockerfile
    container_name: refinery_monitor_agent
    restart: unless-stopped
    stop_grace_period: 10s
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      backend:
        condition: service_healthy
    environment:
      DATABASE_URL: ${DATABASE_URL:-postgresql://refinery:refinery@postgres:5432/refinery}
      REDIS_HOST: redis
      REDIS_PORT: "6379"
      REDIS_PASSWORD: ${REDIS_PASSWORD:-}
      BACKEND_URL: "http://backend:8000"
      MONITOR_INTERVAL: "45"
      QUEUE_STALL_THRESHOLD: "300"
      ERROR_RATE_THRESHOLD: "0.15"
      ALERT_QUEUE: "monitoring:alerts"
    ports:
      - "127.0.0.1:8001:8001"
    healthcheck:
      test: ["CMD-SHELL", "python -c \"import urllib.request; urllib.request.urlopen('http://localhost:8001/health')\""]
      interval: 15s
      timeout: 5s
      retries: 5
      start_period: 20s
    networks:
      - refinery

  healing-agent:
    build:
      context: ./workers
      dockerfile: healing/Dockerfile
    container_name: refinery_healing_agent
    restart: unless-stopped
    stop_grace_period: 10s
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      llm-reason:
        condition: service_healthy
      monitor-agent:
        condition: service_healthy
    environment:
      DATABASE_URL: ${DATABASE_URL:-postgresql://refinery:refinery@postgres:5432/refinery}
      REDIS_HOST: redis
      REDIS_PORT: "6379"
      REDIS_PASSWORD: ${REDIS_PASSWORD:-}
      OLLAMA_BASE_URL: "http://llm-reason:11434"
      REASONING_MODEL: mistral
      AUTO_FIX_ENABLED: "true"
      AUTO_FIX_ALLOW: "restart_worker,requeue_documents,clear_stale_locks"
      AUTO_FIX_DENY: "restart_container,database_operations,delete_data"
      MAX_ACTIONS_PER_HOUR: "10"
      COOLDOWN_BETWEEN_ACTIONS: "120"
      ALERT_QUEUE: "monitoring:alerts"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
    networks:
      - refinery

  # ----------------------------------------------------------
  # AUTONOMOUS ORCHESTRATION
  # ----------------------------------------------------------
  auditor:
    build:
      context: ./workers
      dockerfile: auditor/Dockerfile
    container_name: refinery_auditor
    restart: unless-stopped
    stop_grace_period: 10s
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    environment:
      PYTHONUNBUFFERED: "1"
      DATABASE_URL: ${DATABASE_URL:-postgresql://refinery:refinery@postgres:5432/refinery}
      REDIS_HOST: redis
      REDIS_PORT: "6379"
      REDIS_PASSWORD: ${REDIS_PASSWORD:-}
      AUDIT_INTERVAL: ${AUDIT_INTERVAL:-1800}
    networks:
      - refinery

  orchestrator:
    build:
      context: ./workers
      dockerfile: orchestrator/Dockerfile
    container_name: refinery_orchestrator
    restart: unless-stopped
    stop_grace_period: 10s
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    environment:
      PYTHONUNBUFFERED: "1"
      DATABASE_URL: ${DATABASE_URL:-postgresql://refinery:refinery@postgres:5432/refinery}
      REDIS_HOST: redis
      REDIS_PORT: "6379"
      REDIS_PASSWORD: ${REDIS_PASSWORD:-}
      OLLAMA_BASE_URL: "http://llm-reason:11434"
      REASONING_MODEL: mistral
      ORCHESTRATOR_CYCLE: ${ORCHESTRATOR_CYCLE:-60}
      ORCHESTRATOR_AUTO_RESEARCH: ${ORCHESTRATOR_AUTO_RESEARCH:-true}
      MAX_GPU_QUEUE_ITEMS: "20"
      MAX_CONCURRENT_CRAWLS: "5"
    networks:
      - refinery

  researcher:
    build:
      context: ./workers
      dockerfile: researcher/Dockerfile
    container_name: refinery_researcher
    restart: unless-stopped
    stop_grace_period: 10s
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      searxng:
        condition: service_healthy
    environment:
      PYTHONUNBUFFERED: "1"
      DATABASE_URL: ${DATABASE_URL:-postgresql://refinery:refinery@postgres:5432/refinery}
      REDIS_HOST: redis
      REDIS_PORT: "6379"
      REDIS_PASSWORD: ${REDIS_PASSWORD:-}
      OLLAMA_BASE_URL: "http://llm-reason:11434"
      REASONING_MODEL: mistral
      SEARXNG_URL: "http://searxng:8080"
      AUTONOMOUS_MODE: ${AUTONOMOUS_MODE:-true}
      AUTONOMOUS_INTERVAL: "60"
      AUTONOMOUS_URLS_PER_CYCLE: "4"
      MAX_URLS_PER_HOUR: ${MAX_URLS_PER_HOUR:-60}
      MAX_PER_DOMAIN_PER_HOUR: ${MAX_PER_DOMAIN_PER_HOUR:-5}
      RESEARCH_COOLDOWN: "15"
    networks:
      - refinery

  mcp-server:
    build:
      context: ./workers
      dockerfile: mcp-server/Dockerfile
    container_name: refinery_mcp_server
    restart: unless-stopped
    stop_grace_period: 10s
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      llm-embed:
        condition: service_healthy
    environment:
      PYTHONUNBUFFERED: "1"
      DATABASE_URL: ${DATABASE_URL:-postgresql://refinery:refinery@postgres:5432/refinery}
      REDIS_HOST: redis
      REDIS_PORT: "6379"
      REDIS_PASSWORD: ${REDIS_PASSWORD:-}
      OLLAMA_BASE_URL: "http://llm-embed:11434"
      EMBEDDING_MODEL: nomic-embed-text
    ports:
      - "8002:8002"
    healthcheck:
      test: ["CMD-SHELL", "python -c \"import urllib.request; urllib.request.urlopen('http://localhost:8002/health')\""]
      interval: 15s
      timeout: 5s
      retries: 5
      start_period: 20s
    networks:
      - refinery

networks:
  refinery:
    driver: bridge

volumes:
  postgres_data:
  minio_data:
  ollama_embed_data:
  ollama_reason_data:
  ollama_reason2_data:
